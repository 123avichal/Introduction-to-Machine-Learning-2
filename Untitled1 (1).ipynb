{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd7169a0-ed90-41fa-b505-dca1ee84fc51",
   "metadata": {},
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
    "can they be mitigated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b3ef58-cbeb-44f8-8dd0-4b2d8394590b",
   "metadata": {},
   "source": [
    "Overfitting occurs when our machine learning model tries to cover all the data points or more than the required data points present in the given dataset. Because of this, the model starts caching noise and inaccurate values present in the dataset, and all these factors reduce the efficiency and accuracy of the model. The overfitted model has low bias and high variance.\n",
    "\n",
    " to avoid the Overfitting in Model\n",
    "Both overfitting and underfitting cause the degraded performance of the machine learning model. But the main cause is overfitting, so there are some ways by which we can reduce the occurrence of overfitting in our model.\n",
    "\n",
    "Cross-Validation\n",
    "Training with more data\n",
    "Removing features\n",
    "\n",
    "Underfitting\n",
    "Underfitting occurs when our machine learning model is not able to capture the underlying trend of the data. To avoid the overfitting in the model, the fed of training data can be stopped at an early stage, due to which the model may not learn enough from the training data. As a result, it may fail to find the best fit of the dominant trend in the data.\n",
    "\n",
    "to avoid underfitting:\n",
    "By increasing the training time of the model.\n",
    "By increasing the number of features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232d57a1-85e7-480c-8d83-38264ee28845",
   "metadata": {},
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a381cb49-7e7b-4fd9-bd94-45fbe9956b7d",
   "metadata": {},
   "source": [
    " overfitting cause the degraded performance of the machine learning model. But the main cause is overfitting, so there are some ways by which we can reduce the occurrence of overfitting in our model.\n",
    "\n",
    "Cross-Validation\n",
    "Training with more data\n",
    "Removing features\n",
    "Early stopping the training\n",
    "Regularization\n",
    "Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368f8e6-6232-49c4-9ef6-ef436068fb90",
   "metadata": {},
   "source": [
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1420ce-9532-4ce6-a59f-a2c483ece015",
   "metadata": {},
   "source": [
    "Underfitting occurs when our machine learning model is not able to capture the underlying trend of the data. To avoid the overfitting in the model, the fed of training data can be stopped at an early stage, due to which the model may not learn enough from the training data. As a result, it may fail to find the best fit of the dominant trend in the data.\n",
    "\n",
    "In the case of underfitting, the model is not able to learn enough from the training data, and hence it reduces the accuracy and produces unreliable predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93672993-7b6a-4687-b855-39bfcd761a4a",
   "metadata": {},
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "variance, and how do they affect model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2849ea3-2469-4b36-a36e-a7a726b2da39",
   "metadata": {},
   "source": [
    "If the algorithm is too simple (hypothesis with linear equation) then it may be on high bias and low variance condition and thus is error-prone. If algorithms fit too complex (hypothesis with high degree equation) then it may be on high variance and low bias. In the latter condition, the new entries will not perform well. Well, there is something between both of these conditions, known as a Trade-off or Bias Variance Trade-off. This tradeoff in complexity is why there is a tradeoff between bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a083b492-f7af-4fb8-89eb-552e110b3705",
   "metadata": {},
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "How can you determine whether your model is overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1239601-279b-4932-ab2b-b14feaaf0108",
   "metadata": {},
   "source": [
    "Your model is underfitting the training data when the model performs poorly on the training data. This is because the model is unable to capture the relationship between the input examples (often called X) and the target values (often called Y). Your model is overfitting your training data when you see that the model performs well on the training data but does not perform well on the evaluation data. This is because the model is memorizing the data it has seen and is unable to generalize to unseen examples.\n",
    "\n",
    "Poor performance on the training data could be because the model is too simple (the input features are not expressive enough) to describe the target well. Performance can be improved by increasing model flexibility. To increase model flexibility, try the following:\n",
    "\n",
    "Add new domain-specific features and more feature Cartesian products, and change the types of feature processing used (e.g., increasing n-grams size)\n",
    "\n",
    "Decrease the amount of regularization used\n",
    "\n",
    "If your model is overfitting the training data, it makes sense to take actions that reduce model flexibility. To reduce model flexibility, try the following:\n",
    "\n",
    "Feature selection: consider using fewer feature combinations, decrease n-grams size, and decrease the number of numeric attribute bins.\n",
    "\n",
    "Increase the amount of regularization used.\n",
    "\n",
    "Accuracy on training and test data could be poor because the learning algorithm did not have enough data to learn from. You could improve performance by doing the following:\n",
    "\n",
    "Increase the amount of training data examples.\n",
    "\n",
    "Increase the number of passes on the existing training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324bcb14-3567-49fe-8cd9-70273ca73502",
   "metadata": {},
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "and high variance models, and how do they differ in terms of their performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acc8d96-4fb3-4d53-8dd5-cbb5ba0841b2",
   "metadata": {},
   "source": [
    "High Bias - Low Variance (Underfitting): Predictions are consistent, but inaccurate on average. This can happen when the model uses very few parameters.\n",
    "\n",
    "High Bias - High Variance: Predictions are inconsistent and inaccurate on average.\n",
    "\n",
    "Low Bias - Low Variance: It is an ideal model. But, we cannot achieve this.\n",
    "\n",
    "Low Bias - High Variance (Overfitting): Predictions are inconsistent and accurate on average. This can happen when the model uses a large number of parameters.\n",
    "\n",
    "High Bias can be identified when we have:\n",
    "\n",
    "High training error (higher than acceptable test error)\n",
    "Test error is almost same as training error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d5c5b-a985-404d-9a49-388ba9ab46f9",
   "metadata": {},
   "source": [
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cdef3a-2bde-42d4-aa57-d45b5e807533",
   "metadata": {},
   "source": [
    "Regularization is a technique used to reduce errors by fitting the function appropriately on the given training set and avoiding overfitting. The commonly used regularization techniques are : \n",
    "\n",
    "Lasso Regularization – L1 Regularization\n",
    "Ridge Regularization – L2 Regularization\n",
    "Elastic Net Regularization – L1 and L2 Regularization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
